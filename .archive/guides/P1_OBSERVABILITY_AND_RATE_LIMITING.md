# FASE 2 â€” P1 OBSERVABILITY & RATE LIMITING

**Status:** Planejado  
**DependÃªncias:** P0 Security Layer (âœ… Completo)  
**Tempo Estimado:** 4-6 horas  
**SequÃªncia:** Rate Limiting â†’ Sentry â†’ Structured Logging  

---

## ğŸ¯ Objetivos P1

| Objetivo | Por quÃª | BenefÃ­cio |
|----------|---------|-----------|
| **Rate Limiting** | Proteger endpoints pÃºblicos de brute-force | SeguranÃ§a + UX (sem spam) |
| **Sentry** | Parar de ter erros silenciosos | Debugging + proatividade |
| **Structured Logging** | Rastreabilidade total de operaÃ§Ãµes | Compliance + DevOps |

---

## ğŸ”¹ P1.1 â€” RATE LIMITING (PRIORIDADE ALTA)

### Problema

Sem rate limiting:
- Login: Qualquer um pode brute-force senha infinitamente
- Reset de senha: Spam infinito em email
- APIs pÃºblicas: DOS simples (muitas requisiÃ§Ãµes)

### SoluÃ§Ã£o

**Package:** `rate-limiter-flexible` + `redis` (ou in-memory para comeÃ§ar)

```bash
npm install rate-limiter-flexible redis
```

### Arquitetura

```
lib/
  â””â”€â”€ rate-limiter.ts          â† ConfiguraÃ§Ã£o central
      â”œâ”€â”€ createRateLimiter()  â† Factory function
      â”œâ”€â”€ rateLimitByIp()      â† Middleware genÃ©rico
      â””â”€â”€ rateLimitByUserId()  â† Para authenticated endpoints

middleware.ts  â† Apply rate limits globalmente (opcional)
  â””â”€â”€ Rate limit em /auth/login, /auth/reset-password

app/api/auth/
  â”œâ”€â”€ login/route.ts           â† +3 linhas: rate limit check
  â””â”€â”€ reset-password/route.ts  â† +3 linhas: rate limit check
```

### ImplementaÃ§Ã£o Template

**lib/rate-limiter.ts:**

```typescript
import { RateLimiterRedis, RateLimiterMemory } from 'rate-limiter-flexible';
import { createClient } from 'redis';

// Escolher Redis em prod, memÃ³ria em dev
const useRedis = process.env.NODE_ENV === 'production';

const client = useRedis ? createClient() : null;

// Rate limiters especÃ­ficos
export const loginLimiter = new RateLimiterRedis({
  storeClient: client,
  keyPrefix: 'rl:login',
  points: 5,           // 5 tentativas
  duration: 900,       // por 15 minutos
});

export const resetPasswordLimiter = new RateLimiterRedis({
  storeClient: client,
  keyPrefix: 'rl:reset',
  points: 3,           // 3 tentativas
  duration: 3600,      // por 1 hora
});

export const apiPublicLimiter = new RateLimiterRedis({
  storeClient: client,
  keyPrefix: 'rl:api',
  points: 100,         // 100 requisiÃ§Ãµes
  duration: 60,        // por minuto
});

// Helper function
export async function checkRateLimit(
  limiter: RateLimiterRedis | RateLimiterMemory,
  key: string
): Promise<{ allowed: boolean; remaining: number; resetTime: Date }> {
  try {
    const res = await limiter.consume(key);
    return {
      allowed: true,
      remaining: res.remainingPoints,
      resetTime: new Date(Date.now() + res.msBeforeNext),
    };
  } catch (rateLimiterRes) {
    return {
      allowed: false,
      remaining: 0,
      resetTime: new Date(Date.now() + rateLimiterRes.msBeforeNext),
    };
  }
}
```

**app/api/auth/login/route.ts:**

```typescript
export const POST = safeHandler(async (req: NextRequest, ctx) => {
  // 1. Rate limit check (PRIMEIRO, antes de CPU-heavy ops)
  const ip = req.headers.get('x-forwarded-for') || req.ip || 'unknown';
  const rateLimitResult = await checkRateLimit(loginLimiter, `login:${ip}`);
  
  if (!rateLimitResult.allowed) {
    return NextResponse.json(
      {
        success: false,
        error: {
          code: 'RATE_LIMIT_EXCEEDED',
          message: 'Too many login attempts. Try again later.',
          resetTime: rateLimitResult.resetTime.toISOString(),
        },
      },
      { 
        status: 429,
        headers: {
          'Retry-After': Math.ceil(rateLimitResult.resetTime.getTime() / 1000),
        },
      }
    );
  }

  // 2. Normal login logic...
  const body = await req.json();
  // ... autenticaÃ§Ã£o ...

  return NextResponse.json({ success: true, user });
});
```

### Endpoints a Proteger (Inicialmente)

```
Priority 1 (crÃ­tico):
  POST /api/auth/login              â† 5 tentativas/15min
  POST /api/auth/reset-password     â† 3 tentativas/1h
  POST /api/auth/register           â† 10 tentativas/1h

Priority 2 (importante):
  GET /api/tenants                  â† 100 req/min por IP
  POST /api/users                   â† 50 req/min por tenant
  GET /api/audit-logs               â† 200 req/min por user
```

### ConfiguraÃ§Ã£o Redis (Production)

```bash
# Se usar Redis externo (DigitalOcean, AWS ElastiCache, etc)
REDIS_URL=redis://:password@host:port

# Ou local (development)
docker run -d -p 6379:6379 redis:latest
```

### Testes

```bash
# Teste manual: tentar login 6x + rapid succession
# Esperado: 429 Too Many Requests na 6Âª tentativa

for i in {1..7}; do
  echo "Attempt $i:"
  curl -X POST http://localhost:3000/api/auth/login \
    -H "Content-Type: application/json" \
    -d '{"email":"user@example.com","password":"wrong"}'
  sleep 0.5
done
# Esperado: Ãšltimas 2 tentativas retornam 429
```

---

## ğŸ”¹ P1.2 â€” SENTRY INTEGRATION

### Problema

Errors acontecem em produÃ§Ã£o e ninguÃ©m descobre atÃ© usuÃ¡rio reclamar.

### SoluÃ§Ã£o

Capturar errors automaticamente + send to Sentry dashboard

```bash
npm install @sentry/nextjs @sentry/tracing
```

### Arquitetura

```
lib/
  â””â”€â”€ sentry.ts              â† InicializaÃ§Ã£o + config
      â”œâ”€â”€ initSentry()       â† Setup em servidor
      â””â”€â”€ captureException() â† Wrapper para erros crÃ­ticos

app/
  â””â”€â”€ global-error.ts        â† Fallback error boundary

middleware.ts
  â””â”€â”€ IntegraÃ§Ã£o com Sentry tracing (opcional, mais tarde)
```

### ImplementaÃ§Ã£o Template

**lib/sentry.ts:**

```typescript
import * as Sentry from '@sentry/nextjs';

export function initSentry() {
  const isDev = process.env.NODE_ENV === 'development';
  const dsn = process.env.SENTRY_DSN;

  if (!dsn) {
    console.warn('[SENTRY] DSN not configured, skipping init');
    return;
  }

  Sentry.init({
    dsn,
    environment: process.env.NODE_ENV,
    tracesSampleRate: isDev ? 1.0 : 0.1, // 100% in dev, 10% in prod
    
    // Ignore certain errors
    ignoreErrors: [
      'ResizeObserver loop limit exceeded',
      'Non-Error promise rejection',
      'NetworkError',
    ],

    // Release version (from package.json)
    release: process.env.npm_package_version,

    // Capture breadcrumbs
    integrations: [
      new Sentry.Integrations.Http({ tracing: true }),
      new Sentry.Integrations.OnUncaughtException(),
    ],

    // Before send (adicionar contexto)
    beforeSend(event, hint) {
      // NÃ£o enviar erros de desenvolvimento
      if (isDev && event.level === 'error') {
        console.log('[SENTRY-DEV]', hint.originalException);
        return null; // Skip
      }

      return event;
    },
  });
}

// Wrapper para capturar erros crÃ­ticos
export function captureCriticalError(
  error: Error,
  context: Record<string, any> = {}
) {
  Sentry.captureException(error, {
    tags: {
      severity: 'critical',
    },
    extra: context,
  });
}

// Para erros de negÃ³cio (nÃ£o crÃ­ticos)
export function captureBusinessError(
  message: string,
  context: Record<string, any> = {}
) {
  Sentry.captureMessage(message, {
    level: 'warning',
    extra: context,
  });
}
```

**IntegraÃ§Ã£o em safeHandler:**

```typescript
// lib/api-helpers.ts â€” modificar safeHandler existente

export function safeHandler(
  handler: (req: NextRequest, ctx: RequestContext) => Promise<Response>
) {
  return async (req: NextRequest) => {
    try {
      const ctx = extractContext(req);
      return await handler(req, ctx);
    } catch (error) {
      // JÃ¡ temos logging, agora add Sentry
      const err = error instanceof Error ? error : new Error(String(error));

      // Capture em Sentry
      Sentry.captureException(err, {
        tags: {
          handler: 'api_route',
          method: req.method,
          path: req.nextUrl.pathname,
        },
        extra: {
          requestId: ctx?.requestId,
          userId: ctx?.userId,
          tenantId: ctx?.tenantId,
        },
      });

      return errorResponse(
        'INTERNAL_SERVER_ERROR',
        err.message,
        undefined,
        ctx?.requestId
      );
    }
  };
}
```

### Setup Sentry

1. Criar conta em https://sentry.io
2. Criar projeto Next.js
3. Copiar DSN
4. Add to `.env.local`:
   ```
   SENTRY_DSN=https://key@sentry.io/project-id
   SENTRY_ORG=your-org
   SENTRY_PROJECT=your-project
   ```
5. Inicializar em server startup:
   ```typescript
   // app/layout.tsx ou next.config.js
   import { initSentry } from '@/lib/sentry';
   initSentry();
   ```

### Dashboard Sentry

ApÃ³s setup, vocÃª terÃ¡:
- âœ… Real-time error alerts
- âœ… Source maps para production debugging
- âœ… Performance tracing (opcional)
- âœ… IntegraÃ§Ã£o com Slack/Email

---

## ğŸ”¹ P1.3 â€” STRUCTURED LOGGING (Pino)

### Problema

```
âŒ console.log("user created")
âŒ console.error("Error at xyz")
âŒ Sem contexto tenantId, userId, requestId
```

### SoluÃ§Ã£o

```bash
npm install pino pino-http pino-pretty
```

Criar logger central que emite JSON em prod, bonito em dev.

### Arquitetura

```
lib/
  â””â”€â”€ logger.ts              â† Pino config + setup
      â”œâ”€â”€ createLogger()     â† Factory
      â”œâ”€â”€ withContext()      â† Add tenantId, userId, etc
      â””â”€â”€ child()            â† Nested logging

app/api/
  â””â”€â”€ Todos routes           â† Substituir console.log

middleware.ts
  â””â”€â”€ logger.trace()         â† Log request/response
```

### ImplementaÃ§Ã£o Template

**lib/logger.ts:**

```typescript
import pino, { Logger } from 'pino';

const isDev = process.env.NODE_ENV === 'development';

// Base logger
const baseLogger = pino({
  level: process.env.LOG_LEVEL || (isDev ? 'debug' : 'info'),
  
  // Pretty printing em desenvolvimento
  transport: isDev
    ? {
        target: 'pino-pretty',
        options: {
          colorize: true,
          translateTime: 'SYS:standard',
          ignore: 'pid,hostname',
          singleLine: false,
        },
      }
    : undefined,

  // Em produÃ§Ã£o, enviar pra stack de logs (ELK, Datadog, etc)
  // Aqui serÃ¡ JSON puro, que pode ser coletado
});

// Logger com contexto (RequestContext)
export function createContextLogger(
  requestId: string,
  userId?: string,
  tenantId?: string
): Logger {
  return baseLogger.child({
    requestId,
    userId,
    tenantId,
  });
}

export const logger = baseLogger;
```

**Substituir console.log em handlers:**

```typescript
// âŒ ANTES
console.log('User created:', { userId, email });
console.error('Error:', error.message);

// âœ… DEPOIS
const log = createContextLogger(ctx.requestId, ctx.userId, ctx.tenantId);
log.info({ userId: newUser.id, email: newUser.email }, 'User created');
log.error({ err: error, errorCode }, 'Failed to create user');
```

### Log Levels

```typescript
log.debug({ detail: '...' }, 'Debug info')       // Development only
log.info({ event: '...' }, 'Informational')      // Normal operations
log.warn({ issue: '...' }, 'Warning')            // Suspicious
log.error({ err, code }, 'Error occurred')       // Errors
log.fatal({ err }, 'Fatal error')                // Unrecoverable
```

### ELK Stack (Optional Production)

Para coletar logs em produÃ§Ã£o:

```yaml
# docker-compose.yml (opcional)
version: '3'
services:
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.10.0
    
  kibana:
    image: docker.elastic.co/kibana/kibana:7.10.0
    
  logstash:
    image: docker.elastic.co/logstash/logstash:7.10.0
```

Pino emite JSON que Logstash coleta â†’ Elasticsearch â†’ Kibana (interface)

---

## ğŸ“Š ComparaÃ§Ã£o: Rate Limiting vs Sentry vs Logging

| Aspecto | Rate Limiting | Sentry | Logging |
|---------|---------------|--------|---------|
| **Protege contra** | Brute-force, DOS | Silent errors | Lost context |
| **Quando ativa** | Em produÃ§Ã£o (Redis) | Sempre | Always |
| **Performance** | O(1) check + Redis | Async (nÃ£o-blocking) | Async (nÃ£o-blocking) |
| **Custo** | Redis infra | Sentry SaaS (free tier ok) | Local disk / ELK |
| **Prioridade** | ALTA (security) | ALTA (debugging) | MÃ‰DIA (observability) |

---

## ğŸ”„ Ordem de ImplementaÃ§Ã£o

### Dia 1 (2-3 horas): Rate Limiting
1. Implementar `lib/rate-limiter.ts`
2. Adicionar a `/api/auth/login`
3. Testar brute-force (requisiÃ§Ãµes rÃ¡pidas)
4. Add a `/api/auth/reset-password`

### Dia 2 (1-2 horas): Sentry
1. Setup Sentry account + DSN
2. Implementar `lib/sentry.ts`
3. Integrar em `safeHandler()` existente
4. Testar capturando erro proposital

### Dia 3 (2-3 horas): Structured Logging
1. Implementar `lib/logger.ts` com Pino
2. Substituir `console.log` em 3-4 handlers principais
3. Testar que logs em JSON aparecem em prod
4. Opcional: Setup local ELK para visualizar

**Total: 5-8 horas para P1 completo** âœ…

---

## ğŸ“¦ DependÃªncias NecessÃ¡rias

```bash
npm install rate-limiter-flexible redis @sentry/nextjs pino pino-http pino-pretty
```

**Tamanho adicionado:** ~50 MB (negligÃ­vel)

---

## âœ… Checklist P1 Final

- [ ] P1.1 Rate Limiting
  - [ ] lib/rate-limiter.ts criado
  - [ ] Aplicado em /api/auth/login
  - [ ] Aplicado em /api/auth/reset-password
  - [ ] Testes manuais passam (429 apÃ³s limite)

- [ ] P1.2 Sentry
  - [ ] Conta criada + DSN obtido
  - [ ] lib/sentry.ts implementado
  - [ ] Integrado em safeHandler()
  - [ ] Erro de teste capturado corretamente

- [ ] P1.3 Logging Estruturado
  - [ ] lib/logger.ts com Pino
  - [ ] console.log substituÃ­do em handlers
  - [ ] requestId propagado em todos os logs
  - [ ] Logs JSON aparecem em produÃ§Ã£o

---

## ğŸš€ PrÃ³ximas Fases (AlÃ©m de P1)

**P2 â€” Data & Analytics:**
- Track user behavior
- Page view metrics
- Business analytics

**P3 â€” Performance:**
- Caching strategies
- Query optimization
- CDN integration

**P4 â€” DevOps:**
- Automated deployment
- Monitoring dashboards
- Incident response

---

## ğŸ“ Notas

- Rate limiting com Redis Ã© escalÃ¡vel (mÃºltiplos servidores compartilham estado)
- Sentry Ã© gratuito atÃ© 5k errors/mÃªs (plenty para comeÃ§ar)
- Pino em JSON + ELK Ã© enterprise-grade logging
- Todos 3 componentes sÃ£o non-breaking para cÃ³digo existente

**PrÃ³ximo passo:** ApÃ³s merge de P0, comece com P1.1 (Rate Limiting) â€” Ã© o mais crÃ­tico para seguranÃ§a.
